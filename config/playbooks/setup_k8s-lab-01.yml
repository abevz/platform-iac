---
# ==============================================================================
# ФАЗА 0: DNS SETUP (Pi-hole)
# ==============================================================================
- name: 0. Add K8s Nodes to Pi-hole Local DNS
  hosts: localhost # Выполняется на Ansible-контроллере
  connection: local
  become: no
  tags: [dns_setup]
  
  vars:
    pihole_url: "http://10.10.10.100" # IP Вашего Pi-hole
    # ИСПОЛЬЗУЕМ ТОЧЕЧНУЮ НОТАЦИЮ (pihole.web_password) 
    # в соответствии со структурой extra_vars.sops.yml
    pihole_web_password: "{{ pihole.web_password }}" 
  
  tasks:
    - name: Get list of all K8s hosts and their IPs from dynamic inventory
      ansible.builtin.set_fact:
        k8s_dns_records: |
          {% set records = [] %}
          {% for host in groups['k8s_master'] + groups['k8s_worker'] %}
          {% set records = records + [{'name': hostvars[host].vm_name, 'ip': hostvars[host].ansible_host}] %}
          {% endfor %}
          {{ records }}

    - name: Ensure Pi-hole API Key is set
      ansible.builtin.fail:
        msg: "Не определена переменная 'pihole.web_password' в secrets/ansible/extra_vars.sops.yml"
      when: pihole_web_password is not defined or pihole_web_password | length == 0

    - name: Create / Update A-Records in Pi-hole
      sbarbett.pihole.local_a_record:
        url: "{{ pihole_url }}"
        password: "{{ pihole_web_password }}"
        name: "{{ item.name }}"
        ip: "{{ item.ip }}"
        state: present
      loop: "{{ k8s_dns_records }}"     
# ==============================================================================
# ФАЗА 1: BOOTSTRAP (ВСЕ НОДЫ)
# (k8s_bootstrap_node включает: sysctl, swap, containerd, Kubelet/Kubeadm, 
# Harbor Proxy, AppArmor/Seccomp setup)
# ==============================================================================
- name: 1. Bootstrap All Nodes and Kernel Security (Prereqs, Containerd, Kubelet)
  hosts: k8s_master:k8s_worker
  become: yes
  gather_facts: yes
  tags: [bootstrap]

  vars:
    # Переменные для Harbor. Приходят из SOPS (--extra-vars).
    # Используются ролями k8s_bootstrap_node и k8s_cluster_manager.
    harbor_hostname: "{{ HARBOR_HOSTNAME | default('harbor.bevz.net') }}" 
    harbor_robot_username: "{{ HARBOR_ROBOT_USER | default('k8s-puller') }}"
    harbor_robot_token: "{{ HARBOR_ROBOT_TOKEN | default('') }}"
    k8s_short_version: "1.33" 
    k8s_long_version_debian: "1.33.0-1.1"

  roles:
    # Роль, включающая всю логику install_kubernetes_cluster.yml
    - role: k8s_bootstrap_node

# ==============================================================================
# ФАЗА 2: УПРАВЛЕНИЕ КЛАСТЕРОМ (Init, Join, Secrets)
# (k8s_cluster_manager: kubeadm init, kubeadm join, CSR approve, Harbor Secret)
# ==============================================================================
- name: 2. Manage K8s Cluster State (Init, Join, Verify)
  hosts: k8s_master:k8s_worker
  become: yes
  gather_facts: no
  tags: [cluster_manage]
  
  vars:
    # Повторяем, чтобы быть уверенным в наличии (хотя должны быть из Фазы 1)
    harbor_hostname: "{{ HARBOR_HOSTNAME | default('harbor.bevz.net') }}" 
    harbor_robot_token: "{{ HARBOR_ROBOT_TOKEN | default('') }}" 
    k8s_short_version: "1.33" 
    k8s_long_version_debian: "1.33.0-1.1"
    
  roles:
    # Роль, включающая всю логику initialize_kubernetes_cluster_with_dns.yml, 
    # но без CNI.
    - role: k8s_cluster_manager

# ==============================================================================
# ФАЗА 3: УСТАНОВКА CNI (Выберите ОДНУ роль)
# ==============================================================================
- name: 3. Deploy CNI Plugin (Cilium via Helm)
  hosts: k8s_master
  become: yes
  tags: [cni, cilium]

  roles:
    # ВНИМАНИЕ: Выберите только ОДНУ роль CNI. 
    # В данном примере используется Cilium Helm.
    - role: cilium_install_helm 
    #- role: cilium_install_cli
    #- role: calico_install_helm
    #- role: calico_install_manifest

# ==============================================================================
# ФАЗА 4: УСТАНОВКА ИНСТРУМЕНТОВ БЕЗОПАСНОСТИ
# ==============================================================================
- name: 4. Deploy CKS Security Tooling (Falco and Trivy)
  hosts: k8s_master 
  become: yes
  tags: [security]
  
  roles:
    # Развертывание Falco (DaemonSet через Helm)
    - role: falco_install_package 

    # Установка Trivy CLI на мастер-ноду (для сканирования)
    - role: trivy_package_install 
    
    # Развертывание Trivy Operator (в кластер)
    - role: trivy_operator_deploy
