---
# ==============================================================================
# ФАЗА 1: BOOTSTRAP (ВСЕ НОДЫ)
# (k8s_bootstrap_node включает: sysctl, swap, containerd, Kubelet/Kubeadm, 
# Harbor Proxy, AppArmor/Seccomp setup)
# ==============================================================================
- name: 1. Bootstrap All Nodes and Kernel Security (Prereqs, Containerd, Kubelet)
  hosts: k8s_master:k8s_worker
  become: yes
  gather_facts: yes
  tags: [bootstrap]

  vars:
    # Переменные для Harbor. Приходят из SOPS (--extra-vars).
    # Используются ролями k8s_bootstrap_node и k8s_cluster_manager.
    harbor_hostname: "{{ HARBOR_HOSTNAME | default('harbor.bevz.net') }}" 
    harbor_robot_username: "{{ HARBOR_ROBOT_USER | default('k8s-puller') }}"
    harbor_robot_token: "{{ HARBOR_ROBOT_TOKEN | default('') }}"
    k8s_short_version: "1.33" 
    k8s_long_version_debian: "1.33.0-1.1"

  roles:
    # Роль, включающая всю логику install_kubernetes_cluster.yml
    - role: k8s_bootstrap_node

# ==============================================================================
# ФАЗА 2: УПРАВЛЕНИЕ КЛАСТЕРОМ (Init, Join, Secrets)
# (k8s_cluster_manager: kubeadm init, kubeadm join, CSR approve, Harbor Secret)
# ==============================================================================
- name: 2. Manage K8s Cluster State (Init, Join, Verify)
  hosts: k8s_master:k8s_worker
  become: yes
  gather_facts: no
  tags: [cluster_manage]
  
  vars:
    # Повторяем, чтобы быть уверенным в наличии (хотя должны быть из Фазы 1)
    harbor_hostname: "{{ HARBOR_HOSTNAME | default('harbor.bevz.net') }}" 
    harbor_robot_token: "{{ HARBOR_ROBOT_TOKEN | default('') }}" 
    k8s_short_version: "1.33" 
    k8s_long_version_debian: "1.33.0-1.1"
    
  roles:
    # Роль, включающая всю логику initialize_kubernetes_cluster_with_dns.yml, 
    # но без CNI.
    - role: k8s_cluster_manager

# ==============================================================================
# ФАЗА 3: УСТАНОВКА CNI (Выберите ОДНУ роль)
# ==============================================================================
- name: 3. Deploy CNI Plugin (Cilium via Helm)
  hosts: k8s_master
  become: yes
  tags: [cni, cilium]

  roles:
    # ВНИМАНИЕ: Выберите только ОДНУ роль CNI. 
    # В данном примере используется Cilium Helm.
    - role: cilium_install_helm 
    #- role: cilium_install_cli
    #- role: calico_install_helm
    #- role: calico_install_manifest

# ==============================================================================
# ФАЗА 3.5: ВЕРИФИКАЦИЯ НОД И CSR (ПОСЛЕ CNI)
# ==============================================================================
- name: 3.5. Verify Node Readiness and Approve CSRs (Post-CNI)
  hosts: k8s_master
  become: yes
  gather_facts: no
  tags: [cluster_verify] # Можно добавить новый тег

  tasks:
    - name: Wait for all nodes to report Ready status (post-CNI)
      ansible.builtin.command: "kubectl wait --for=condition=Ready nodes --all --timeout=300s"
      changed_when: false # Ожидание не является изменением

    - name: Wait until all worker CSRs are created
      ansible.builtin.command: >
        kubectl get csr -o jsonpath='{.items[?(@.spec.signerName=="kubernetes.io/kubelet-serving")].metadata.name}'
      register: pending_csr_names
      # 'until' должен использовать 'groups', а не 'hostvars'
      until: "pending_csr_names.stdout.split(' ') | length >= (groups['k8s_worker'] | length)"
      retries: 30
      delay: 10
      changed_when: false

    - name: Approve all found kubelet serving CSRs
      ansible.builtin.command: "kubectl certificate approve {{ item }}"
      loop: "{{ pending_csr_names.stdout.split(' ') }}"
      when: "pending_csr_names.stdout | length > 0"
      changed_when: true

    - name: Final cluster status verification
      ansible.builtin.shell: kubectl get nodes -o wide
      register: final_cluster_status
      changed_when: false

    - name: Display final cluster status
      ansible.builtin.debug:
        msg: |
          Final Cluster Status:
          {{ final_cluster_status.stdout }}
      
# ==============================================================================
# ФАЗА 4: УСТАНОВКА ИНСТРУМЕНТОВ БЕЗОПАСНОСТИ
# ==============================================================================
- name: 4. Deploy CKS Security Tooling (Falco and Trivy)
  hosts: k8s_master 
  become: yes
  tags: [security]
  
  roles:
    # Развертывание Falco (DaemonSet через Helm)
    - role: falco_install_package 

    # Установка Trivy CLI на мастер-ноду (для сканирования)
    - role: trivy_package_install 
    
    # Развертывание Trivy Operator (в кластер)
    - role: trivy_operator_deploy
